// Multi-provider AI Service
RED.openAIService = (function() {
    // Legacy config for backward compatibility
    const config = {
        apiKey: "",
        model: "gpt-4o",
        temperature: 0.7
    };

    // Storage keys
    const STORAGE_KEY_AI_PROVIDERS = 'aiProviders';
    const STORAGE_KEY_AI_ASSISTANT = 'aiAssistant';
    const LEGACY_STORAGE_KEY = 'node-red-openai-api-key';

    // Function to get API key from new storage structure
    function getApiKey(providerId, apiKeyId) {
        const aiProviders = RED.settings.get(STORAGE_KEY_AI_PROVIDERS, {});
        const provider = aiProviders[providerId];
        if (!provider || !provider.keys) return null;
        
        const key = provider.keys.find(k => k.id === apiKeyId && k.enabled);
        return key ? key.apiKey : null;
    }

    // Function to get all enabled API keys for a provider
    function getProviderKeys(providerId) {
        const aiProviders = RED.settings.get(STORAGE_KEY_AI_PROVIDERS, {});
        const provider = aiProviders[providerId];
        return provider && provider.keys ? provider.keys.filter(k => k.enabled) : [];
    }

    // Function to load configuration from Node-RED settings (legacy support)
    function loadConfig() {
        // First try to load from localStorage (legacy)
        const savedApiKey = localStorage.getItem(LEGACY_STORAGE_KEY);
        if (savedApiKey && savedApiKey.trim().length > 0) {
            config.apiKey = savedApiKey;
        }
        
        // Then check Node-RED settings (will override localStorage if present)
        if (RED.settings?.openai) {
            const { apiKey, model, temperature } = RED.settings.openai;
            if (apiKey) config.apiKey = apiKey;
            if (model) config.model = model;
            if (temperature !== undefined) config.temperature = temperature;
        }
    }
    
    // Function to update API key (legacy support)
    function updateApiKey(apiKey) {
        if (apiKey && apiKey.trim().length > 0) {
            config.apiKey = apiKey;
            return true;
        }
        return false;
    }

    function getSystemPrompt(availableNodeTypes, nodesInWorkspace) {
        // Use cached node types if available
        var cachedNodeTypes = availableNodeTypes;
        if (RED.aiContextManager) {
            cachedNodeTypes = RED.aiContextManager.getCachedNodeTypes(availableNodeTypes);
        }
        
        // Use cached workspace if available
        var cachedWorkspace = nodesInWorkspace;
        if (RED.aiContextManager) {
            cachedWorkspace = RED.aiContextManager.getCachedWorkspaceSummary(nodesInWorkspace);
        }
        
        return {
            role: "system",
            content: `You are a Node-RED assistant with three primary functions:

1. ANSWER QUESTIONS
   When providing general information, use normal_reply function.
   - Provide Node-RED knowledge, concepts, and functionality explanations
   - Share best practices and optimization tips
   - Help troubleshoot common issues

2. CREATE NEW FLOWS
   When creating a new flow, use create_flow function with valid JSON.
   - Generate complete, importable Node-RED flow JSON from user descriptions
   - Include only necessary nodes from the available node types
   - Ensure all nodes have unique names and IDs
   - Changes that depend on other changes must be added after the changes they depend on. For example, if you want to add a debug node to see the output of an existing function node:
     1. First add the change to create the debug node
     2. Then add the change to update the function node's wires to connect to the new debug node

3. UPDATE EXISTING FLOWS
   When modifying existing flows, use update_flow function with valid JSON.
   - Preserve all existing node IDs
   - Generate a list of changes one by one as shown in the function definitions.
   - Ensure wires are correctly specified for all nodes
   - Preserve the position of the nodes if it wasn't explicitly changed.

WORKSPACE CONTEXT:
${cachedWorkspace ? `Currently visible nodes: ${JSON.stringify(cachedWorkspace)}` : 'No nodes currently in workspace'}

AVAILABLE NODE TYPES:
${JSON.stringify(cachedNodeTypes)}

CRITICAL REQUIREMENTS:
- Only use node types from the available list above
- Do not create custom nodes when standard nodes will work
- Generate valid, properly formatted JSON
- Wire connections must be flat arrays of strings
- For new flows: generate unique IDs for all nodes
- For updates: preserve all existing node IDs
- Always verify wire connections are correctly specified`
        };
    }

    // Rough token estimation: ~4 characters per token
    function estimateTokens(text) {
        if (!text) return 0;
        if (typeof text !== 'string') {
            text = JSON.stringify(text);
        }
        return Math.ceil(text.length / 4);
    }

    /**
     * Summarize node types for questions (minimal context)
     */
    function summarizeNodeTypes(nodeTypes) {
        if (!nodeTypes) return null;
        
        var summary = {};
        for (var type in nodeTypes) {
            if (nodeTypes.hasOwnProperty(type)) {
                var nodeType = nodeTypes[type];
                summary[type] = {
                    name: nodeType.name || type,
                    category: nodeType.category || 'unknown',
                    help: nodeType.help || '',
                    // Exclude full schema, properties, etc. to save tokens
                };
            }
        }
        return summary;
    }

    /**
     * Summarize workspace for questions (very minimal - just counts and types)
     */
    function summarizeWorkspaceForQuestions(workspace) {
        if (!workspace || !Array.isArray(workspace) || workspace.length === 0) {
            return null;
        }
        
        // For questions, just return summary stats
        var nodeTypes = {};
        workspace.forEach(function(node) {
            var type = node.type || 'unknown';
            nodeTypes[type] = (nodeTypes[type] || 0) + 1;
        });
        
        return {
            nodeCount: workspace.length,
            nodeTypes: nodeTypes,
            // No individual node details needed for questions
        };
    }

    /**
     * Summarize workspace for flow creation (minimal info to avoid conflicts)
     */
    function summarizeWorkspace(workspace) {
        if (!workspace || !Array.isArray(workspace) || workspace.length === 0) {
            return null;
        }
        
        // Return minimal info: just IDs, types, and names for conflict detection
        return workspace.map(function(node) {
            return {
                id: node.id,
                type: node.type,
                name: node.name || node.id,
                x: node.x,
                y: node.y
                // Exclude full node internals to save tokens
            };
        });
    }

    function estimateMessageTokens(message) {
        let tokens = 0;
        if (message.role) tokens += 2; // role overhead
        if (message.content) {
            tokens += estimateTokens(message.content);
        }
        if (message.name) tokens += estimateTokens(message.name);
        return tokens;
    }

    /**
     * Check if message is important (should be preserved)
     */
    function isImportantMessage(message) {
        // Preserve messages that contain flows, errors, or important decisions
        if (message.isFlow || message.isUpdate) {
            return true;
        }
        if (message.role === 'assistant' && message.content) {
            var content = message.content.toLowerCase();
            if (content.includes('error') || content.includes('warning') || 
                content.includes('failed') || content.includes('success')) {
                return true;
            }
        }
        return false;
    }

    /**
     * Create summary of messages
     */
    function createMessageSummary(messages) {
        if (!messages || messages.length === 0) {
            return '';
        }
        
        var summary = [];
        var flowCount = 0;
        var updateCount = 0;
        var errorCount = 0;
        
        messages.forEach(function(msg) {
            if (msg.isFlow) {
                flowCount++;
                if (msg.content) {
                    summary.push('Created flow: ' + (msg.content.substring(0, 100) || 'flow'));
                }
            } else if (msg.isUpdate) {
                updateCount++;
                if (msg.content) {
                    summary.push('Updated flow: ' + (msg.content.substring(0, 100) || 'flow'));
                }
            } else if (msg.role === 'assistant' && msg.content) {
                var content = msg.content.toLowerCase();
                if (content.includes('error') || content.includes('failed')) {
                    errorCount++;
                    summary.push('Error: ' + (msg.content.substring(0, 100) || 'error'));
                }
            }
        });
        
        var summaryText = '';
        if (flowCount > 0) summaryText += flowCount + ' flow(s) created. ';
        if (updateCount > 0) summaryText += updateCount + ' flow update(s). ';
        if (errorCount > 0) summaryText += errorCount + ' error(s). ';
        if (summary.length > 0) {
            summaryText += 'Details: ' + summary.join('; ');
        }
        
        return summaryText || 'Previous conversation (' + messages.length + ' messages)';
    }

    /**
     * Summarize old messages while preserving recent ones
     */
    function summarizeHistory(history, keepRecent) {
        keepRecent = keepRecent || 10;
        
        if (history.length <= keepRecent) {
            return history;
        }
        
        var recent = history.slice(-keepRecent);
        var old = history.slice(0, -keepRecent);
        
        // Separate important messages from general conversation
        var importantOld = [];
        var generalOld = [];
        
        old.forEach(function(msg) {
            if (isImportantMessage(msg)) {
                importantOld.push(msg);
            } else {
                generalOld.push(msg);
            }
        });
        
        // Create summary of general conversation
        var summaryMessage = null;
        if (generalOld.length > 0) {
            var summaryText = createMessageSummary(generalOld);
            summaryMessage = {
                role: 'system',
                content: 'Previous conversation summary: ' + summaryText,
                isSummary: true
            };
        }
        
        // Combine: important old messages + summary + recent messages
        var result = importantOld.slice();
        if (summaryMessage) {
            result.push(summaryMessage);
        }
        result = result.concat(recent);
        
        return result;
    }

    /**
     * Intelligent truncation: prioritize important messages
     */
    function intelligentTruncate(history, maxTokens) {
        if (!history || history.length === 0) {
            return [];
        }
        
        // Separate important and regular messages
        var important = [];
        var regular = [];
        
        history.forEach(function(msg, index) {
            if (isImportantMessage(msg)) {
                important.push({ msg: msg, index: index, tokens: estimateMessageTokens(msg) });
            } else {
                regular.push({ msg: msg, index: index, tokens: estimateMessageTokens(msg) });
            }
        });
        
        // Always keep important messages
        var result = [];
        var usedTokens = 0;
        
        // Add important messages first (in order)
        important.forEach(function(item) {
            if (usedTokens + item.tokens <= maxTokens) {
                result.push({ msg: item.msg, index: item.index });
                usedTokens += item.tokens;
            }
        });
        
        // Add recent regular messages (most recent first)
        var remainingTokens = maxTokens - usedTokens;
        for (var i = regular.length - 1; i >= 0; i--) {
            var item = regular[i];
            if (usedTokens + item.tokens <= maxTokens) {
                result.push({ msg: item.msg, index: item.index });
                usedTokens += item.tokens;
            } else {
                break;
            }
        }
        
        // Sort by original index to maintain order
        result.sort(function(a, b) {
            return a.index - b.index;
        });
        
        // Return just the messages
        return result.map(function(item) {
            return item.msg;
        });
    }

    /**
     * Detect operation type from user message
     */
    function detectOperationType(userMessage, nodesInWorkspace) {
        var message = userMessage.toLowerCase();
        
        // Check for flow creation keywords
        if (message.includes('create') || message.includes('make') || 
            message.includes('build') || message.includes('generate') ||
            message.includes('new flow')) {
            return 'create_flow';
        }
        
        // Check for flow update keywords
        if (message.includes('update') || message.includes('modify') || 
            message.includes('change') || message.includes('edit') ||
            message.includes('add') || message.includes('remove') ||
            message.includes('delete') || message.includes('connect') ||
            message.includes('disconnect')) {
            // If workspace has nodes, likely an update
            if (nodesInWorkspace && nodesInWorkspace.length > 0) {
                return 'update_flow';
            }
        }
        
        // Default to question
        return 'question';
    }

    function prepareMessages(userMessage, conversationHistory, availableNodeTypes, nodesInWorkspace, maxContextTokens) {
        // Detect operation type for conditional context
        var operationType = detectOperationType(userMessage, nodesInWorkspace);
        
        // Build context based on operation type
        var contextNodeTypes = availableNodeTypes;
        var contextWorkspace = nodesInWorkspace;
        
        if (operationType === 'question') {
            // For questions, use minimal context
            // Just node type names and descriptions, not full schemas
            contextNodeTypes = summarizeNodeTypes(availableNodeTypes);
            // For questions, send only summary stats (not full workspace)
            contextWorkspace = summarizeWorkspaceForQuestions(nodesInWorkspace);
        } else if (operationType === 'create_flow') {
            // For flow creation, use full node types but summary workspace
            contextNodeTypes = availableNodeTypes;
            contextWorkspace = summarizeWorkspace(nodesInWorkspace);
        } else {
            // For flow updates, use full context (required for quality)
            contextNodeTypes = availableNodeTypes;
            contextWorkspace = nodesInWorkspace;
        }
        
        // Summarize old history if needed (keep last 10 messages verbatim)
        var processedHistory = summarizeHistory(conversationHistory, 10);
        
        const systemPrompt = getSystemPrompt(contextNodeTypes, contextWorkspace);
        const systemTokens = estimateTokens(systemPrompt.content);
        const functionTokens = 216; // Approximate overhead for function definitions
        const userMessageTokens = estimateTokens(userMessage);
        
        // Reserve tokens for system prompt, functions, user message, and some buffer
        const reservedTokens = systemTokens + functionTokens + userMessageTokens + 500;
        const availableForHistory = maxContextTokens ? Math.max(0, maxContextTokens - reservedTokens) : Infinity;
        
        // If we have a context limit, use intelligent truncation
        if (availableForHistory < Infinity && processedHistory.length > 0) {
            var truncatedHistory = intelligentTruncate(processedHistory, availableForHistory);
            
            if (truncatedHistory.length < processedHistory.length) {
                var truncatedCount = processedHistory.length - truncatedHistory.length;
                console.warn(`Chat history truncated: removed ${truncatedCount} older messages to fit context window (${maxContextTokens} tokens)`);
                // Store truncation info for user notification
                prepareMessages._lastTruncation = {
                    originalCount: conversationHistory.length,
                    keptCount: truncatedHistory.length,
                    removedCount: truncatedCount,
                    maxContextTokens: maxContextTokens
                };
            } else {
                prepareMessages._lastTruncation = null;
            }
            
            return [...truncatedHistory, {
                role: "user",
                content: userMessage
            }];
        }
        
        prepareMessages._lastTruncation = null;
        
        // No limit or limit is high enough, use processed history
        return [...processedHistory, {
            role: "user",
            content: userMessage
        }];
    }

    function getFunctionDefinitions() {
        return [
            {
                type: "function",
                function: {
                    name: "normal_reply",
                    description: "Used for standard conversation when the user is not requesting a flow to be created",
                    parameters: {
                        type: "object",
                        properties: {
                            response: {
                                type: "string",
                                description: "The assistant's response to the user's query"
                            }
                        },
                        required: ["response"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "create_flow",
                    description: "Creates a Node-RED flow based on the user description",
                    parameters: {
                        type: "object",
                        properties: {
                            flow: {
                                type: "string",
                                description: "The stringified JSON representation of the Node-RED flow that can be imported directly. Must be a valid JSON string."
                            },
                            explanation: {
                                type: "string",
                                description: "A detailed explanation of the flow, how it works, and any special considerations"
                            }
                        },
                        required: ["flow", "explanation"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "update_flow",
                    description: "Updates an existing flow using git-like change operations",
                    parameters: {
                        type: "object",
                        properties: {
                            changes: {
                                type: "array",
                                description: "List of git-like operations to apply to the flow",
                                items: {
                                    type: "object",
                                    properties: {
                                        operation: {
                                            type: "string",
                                            enum: ["add", "modify", "remove"],
                                            description: "Type of change operation"
                                        },
                                        nodeId: {
                                            type: "string",
                                            description: "ID of the node being modified"
                                        },
                                        value: {
                                            type: "string",
                                            description: "Entire Stringified JSON of the node to be added or modified"
                                        },
                                        description: {
                                            type: "string",
                                            description: "Description of the change"
                                        }
                                    },
                                    required: ["operation", "nodeId", "value", "description"]
                                }
                            },
                            explanation: {
                                type: "string",
                                description: "Overall explanation of the changes shown to the user"
                            }
                        },
                        required: ["changes", "explanation"]
                    }
                }
            }
        ];
    }

    // OpenAI API call
    async function callOpenAIAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature) {
        if (!apiKey) {
            throw new Error("OpenAI API key not configured. Please set it in the settings.");
        }

        const systemPrompt = getSystemPrompt(availableNodeTypes, nodesInWorkspace).content;
        const openaiMessages = [
            { role: "system", content: systemPrompt },
            ...messages.map(msg => {
                if (typeof msg === "string") {
                    return { role: "user", content: msg };
                }
                if (msg.role && msg.content) {
                    return msg;
                }
                return { 
                    role: "user", 
                    content: typeof msg === "object" ? JSON.stringify(msg) : String(msg)
                };
            })
        ];

        // Add important instructions to the last user message
        if (openaiMessages.length > 0) {
            const lastMessage = openaiMessages[openaiMessages.length - 1];
            if (lastMessage.role === "user") {
                lastMessage.content += "\n\nIMPORTANT: Beautify always the workflow based on the position and subflows";
                lastMessage.content += "\n\nIMPORTANT: If a node red plugin is needed, ask the user to install it first before creating the flow. If the user already has it installed, just use it.";
                lastMessage.content += "\n\nIMPORTANT: Always make sure changes in the update flow is a list of changes not a string.";
            }
        }

        try {
            const functionDefinitions = getFunctionDefinitions();
            const requestBody = {
                model: model || "gpt-4o",
                messages: openaiMessages,
                temperature: temperature || 0.7,
                max_tokens: 4000
            };

            if (functionDefinitions.length > 0) {
                requestBody.tools = functionDefinitions;
                requestBody.tool_choice = "auto";
            }
            
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify(requestBody)
            });

            const data = await response.json();
            
            if (!response.ok) {
                console.error('OpenAI API Error:', data);
                throw new Error(`OpenAI API Error: ${data.error?.message || 'Unknown error'}`);
            }

            return data;
        } catch (error) {
            console.error("OpenAI API call failed:", error);
            throw error;
        }
    }

    // Anthropic API call
    async function callAnthropicAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature) {
        if (!apiKey) {
            throw new Error("Anthropic API key not configured. Please set it in the settings.");
        }

        const systemPrompt = getSystemPrompt(availableNodeTypes, nodesInWorkspace).content;
        
        // Convert messages to Anthropic format (no system message in array, separate system param)
        const anthropicMessages = messages.map(msg => {
            if (typeof msg === "string") {
                return { role: "user", content: msg };
            }
            if (msg.role && msg.content) {
                // Anthropic uses "user" and "assistant" roles
                return {
                    role: msg.role === "system" ? "user" : msg.role,
                    content: msg.content
                };
            }
            return { 
                role: "user", 
                content: typeof msg === "object" ? JSON.stringify(msg) : String(msg)
            };
        });

        // Add important instructions to the last user message
        if (anthropicMessages.length > 0 && anthropicMessages[anthropicMessages.length - 1].role === "user") {
            anthropicMessages[anthropicMessages.length - 1].content += "\n\nIMPORTANT: Beautify always the workflow based on the position and subflows";
            anthropicMessages[anthropicMessages.length - 1].content += "\n\nIMPORTANT: If a node red plugin is needed, ask the user to install it first before creating the flow. If the user already has it installed, just use it.";
            anthropicMessages[anthropicMessages.length - 1].content += "\n\nIMPORTANT: Always make sure changes in the update flow is a list of changes not a string.";
        }

        try {
            const functionDefinitions = getFunctionDefinitions();
            const requestBody = {
                model: model || "claude-3-5-sonnet-20241022",
                max_tokens: 4096,
                system: systemPrompt,
                messages: anthropicMessages,
                temperature: temperature || 0.7
            };

            // Convert tools format for Anthropic
            if (functionDefinitions.length > 0) {
                requestBody.tools = functionDefinitions.map(tool => ({
                    name: tool.function.name,
                    description: tool.function.description,
                    input_schema: tool.function.parameters
                }));
            }

            const response = await fetch('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': apiKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify(requestBody)
            });

            const data = await response.json();

            if (!response.ok) {
                console.error('Anthropic API Error:', data);
                throw new Error(`Anthropic API Error: ${data.error?.message || 'Unknown error'}`);
            }

            // Convert Anthropic response to OpenAI-like format for unified handling
            var converted = {
                choices: [{
                    message: {
                        content: data.content && data.content.length > 0 && data.content[0].type === 'text' 
                            ? data.content[0].text 
                            : null,
                        tool_calls: data.content && data.content.length > 0 && data.content[0].type === 'tool_use'
                            ? data.content.filter(c => c.type === 'tool_use').map(c => ({
                                id: c.id,
                                type: 'function',
                                function: {
                                    name: c.name,
                                    arguments: JSON.stringify(c.input)
                                }
                            }))
                            : null
                    }
                }]
            };
            
            // Preserve original usage for token tracking
            if (data.usage) {
                converted.usage = data.usage;
            }
            
            return converted;
        } catch (error) {
            console.error("Anthropic API call failed:", error);
            throw error;
        }
    }

    // Gemini API call
    async function callGeminiAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature) {
        if (!apiKey) {
            throw new Error("Gemini API key not configured. Please set it in the settings.");
        }

        const systemPrompt = getSystemPrompt(availableNodeTypes, nodesInWorkspace).content;
        
        // Convert messages to Gemini format
        const geminiContents = [];
        
        // Add system instruction as first user message
        geminiContents.push({
            role: "user",
            parts: [{ text: systemPrompt }]
        });
        geminiContents.push({
            role: "model",
            parts: [{ text: "I understand. I'm a Node-RED assistant and will help with questions, creating flows, and updating flows." }]
        });

        // Convert conversation messages
        messages.forEach(msg => {
            if (typeof msg === "string") {
                geminiContents.push({
                    role: "user",
                    parts: [{ text: msg }]
                });
            } else if (msg.role && msg.content) {
                geminiContents.push({
                    role: msg.role === "assistant" ? "model" : "user",
                    parts: [{ text: msg.content }]
                });
            }
        });

        // Add important instructions to the last user message
        if (geminiContents.length > 0 && geminiContents[geminiContents.length - 1].role === "user") {
            const lastPart = geminiContents[geminiContents.length - 1].parts[0];
            lastPart.text += "\n\nIMPORTANT: Beautify always the workflow based on the position and subflows";
            lastPart.text += "\n\nIMPORTANT: If a node red plugin is needed, ask the user to install it first before creating the flow. If the user already has it installed, just use it.";
            lastPart.text += "\n\nIMPORTANT: Always make sure changes in the update flow is a list of changes not a string.";
        }

        try {
            const functionDefinitions = getFunctionDefinitions();
            const requestBody = {
                contents: geminiContents,
                generationConfig: {
                    temperature: temperature || 0.7,
                    maxOutputTokens: 4096
                }
            };

            // Convert tools format for Gemini
            if (functionDefinitions.length > 0) {
                requestBody.tools = [{
                    functionDeclarations: functionDefinitions.map(tool => ({
                        name: tool.function.name,
                        description: tool.function.description,
                        parameters: tool.function.parameters
                    }))
                }];
            }

            const modelName = model || "gemini-1.5-pro";
            const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${apiKey}`;

            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody)
            });

            const data = await response.json();

            if (!response.ok || data.error) {
                console.error('Gemini API Error:', data);
                throw new Error(`Gemini API Error: ${data.error?.message || 'Unknown error'}`);
            }

            // Convert Gemini response to OpenAI-like format
            const candidate = data.candidates && data.candidates[0];
            const content = candidate && candidate.content;
            const parts = content && content.parts;
            const textPart = parts && parts.find(p => p.text);
            const functionCallPart = parts && parts.find(p => p.functionCall);

            // Preserve original response for token tracking
            var converted = {
                choices: [{
                    message: {
                        content: textPart ? textPart.text : null,
                        tool_calls: functionCallPart ? [{
                            id: functionCallPart.functionCall.name + "-" + Date.now(),
                            type: 'function',
                            function: {
                                name: functionCallPart.functionCall.name,
                                arguments: JSON.stringify(functionCallPart.functionCall.args || {})
                            }
                        }] : null
                    }
                }]
            };
            
            // Attach original usage metadata for token tracking
            if (data.usageMetadata) {
                converted.usageMetadata = data.usageMetadata;
            }
            
            return converted;
        } catch (error) {
            console.error("Gemini API call failed:", error);
            throw error;
        }
    }

    // Safe JSON parsing utility
    function safeParseJSON(jsonString) {
        if (!jsonString || typeof jsonString !== 'string') {
            return null;
        }

        // Trim whitespace
        jsonString = jsonString.trim();
        
        // Try to find the first valid JSON object/array
        // Sometimes AI responses have extra text after JSON
        let parsed = null;
        let startIdx = 0;
        
        // Look for first { or [
        for (let i = 0; i < jsonString.length; i++) {
            if (jsonString[i] === '{' || jsonString[i] === '[') {
                startIdx = i;
                break;
            }
        }
        
        // Try parsing from different positions
        for (let endIdx = jsonString.length; endIdx > startIdx; endIdx--) {
            try {
                const candidate = jsonString.substring(startIdx, endIdx).trim();
                if (candidate.length === 0) continue;
                
                // Check if it looks like valid JSON (starts with { or [)
                if (candidate[0] === '{' || candidate[0] === '[') {
                    parsed = JSON.parse(candidate);
                    break;
                }
            } catch (e) {
                // Continue trying shorter strings
                continue;
            }
        }
        
        if (parsed !== null) {
            return parsed;
        }

        // Fallback: try original sanitization approach
        try {
            const sanitizedString = jsonString
                .replace(/[\u0000-\u0009\u000B-\u000C\u000E-\u001F\u007F-\u009F]/g, "")
                .replace(/\\(?!["\\/bfnrt])/g, "\\\\");
            return JSON.parse(sanitizedString);
        } catch (err) {
            console.error("Failed to parse JSON after sanitization:", err, "Original string:", jsonString.substring(0, 100));
            return null;
        }
    }

    function handleNormalReply(functionArgs, nodesInWorkspace) {
        return {
            success: true,
            isFlow: false,
            isUpdate: false,
            content: functionArgs.response
        };
    }

    function handleCreateFlow(functionArgs, nodesInWorkspace) {
        try {
            const flowJson = safeParseJSON(functionArgs.flow);
            if (!flowJson) {
                throw new Error("Invalid flow JSON");
            }
            return {
                success: true,
                isFlow: true,
                flow: flowJson,
                description: functionArgs.explanation
            };
        } catch (e) {
            console.error("Error parsing flow JSON:", e);
            return {
                success: false,
                isFlow: false,
                content: "I tried to create a flow but encountered an error in the JSON format. Please try again with a simpler description.",
                error: e.message
            };
        }
    }

    function handleUpdateFlow(functionArgs, nodesInWorkspace) {
        if (!Array.isArray(functionArgs.changes)) {
            functionArgs.changes = safeParseJSON(functionArgs.changes);
        }

        try {
            const sanitizedChanges = functionArgs.changes.map(change => {
                const sanitizedChange = {...change};
                if (sanitizedChange.value && typeof sanitizedChange.value === 'string') {
                    // Validate JSON but keep original string value
                    const parsed = safeParseJSON(sanitizedChange.value);
                    if (!parsed) {
                        throw new Error(`Invalid JSON in change value for node ${sanitizedChange.nodeId}`);
                    }
                }
                return sanitizedChange;
            });
            
            const flow = applyFlowChanges(nodesInWorkspace, sanitizedChanges);
            return {
                success: true,
                isFlow: false,
                isUpdate: true,
                flow: flow,
                changes: sanitizedChanges.map(change => ({
                    ...change,
                    timestamp: Date.now(),
                    status: 'pending'
                })),
                description: functionArgs.explanation
            };
        } catch (e) {
            console.error("Error in handleUpdateFlow:", e);
            return {
                success: false,
                isFlow: false,
                isUpdate: true,
                content: "Error processing flow updates: " + e.message
            };
        }
    }

    function applyFlowChanges(currentFlow, changes) {
        // Create a copy to avoid mutating the original array
        const newFlow = [...currentFlow];

        changes.forEach(change => {
            const { operation, nodeId } = change;
            let nodeValue;
            
            try {
                if (change.value && change.value !== "") {
                    nodeValue = safeParseJSON(change.value);
                } else {
                    nodeValue = "";
                }
            } catch (e) {
                console.error(`Error parsing value for node ${nodeId}:`, e);
                return;
            }

            switch (operation) {
                case 'add':
                    newFlow.push(nodeValue);
                    break;
                case 'modify':
                    const nodeIndex = newFlow.findIndex(node => node.id === nodeId);
                    if (nodeIndex !== -1) {
                        newFlow[nodeIndex] = { ...newFlow[nodeIndex], ...nodeValue };
                    }
                    break;
                case 'remove':
                    const deleteIndex = newFlow.findIndex(node => node.id === nodeId);
                    if (deleteIndex !== -1) {
                        newFlow.splice(deleteIndex, 1);
                    }
                    break;
            }
        });

        return newFlow;
    }

    // Main processMessage function - now supports multiple providers
    async function processMessage(userMessage, conversationHistory, availableNodeTypes, nodesInWorkspace, provider, model, apiKeyId) {
        // Get model context window limit
        let maxContextTokens = null;
        if (provider && model) {
            const modelConfig = RED.aiModels.getModel(provider, model);
            if (modelConfig && modelConfig.contextWindow) {
                maxContextTokens = modelConfig.contextWindow;
            }
        }
        
        const messages = prepareMessages(userMessage, conversationHistory, availableNodeTypes, nodesInWorkspace, maxContextTokens);
        
        // Capture truncation info if history was truncated
        const truncationInfo = prepareMessages._lastTruncation || null;
        
        // Get API key
        let apiKey = null;
        let temperature = 0.7;
        
        if (provider && apiKeyId) {
            // New multi-provider flow
            apiKey = getApiKey(provider, apiKeyId);
            if (!apiKey) {
                throw new Error(`${provider} API key not found. Please configure it in settings.`);
            }
            // Get model config for temperature
            const modelConfig = RED.aiModels.getModel(provider, model);
            if (modelConfig) {
                temperature = modelConfig.defaultTemperature;
            }
        } else {
            // Legacy flow - use OpenAI with old config
            provider = "openai";
            model = model || config.model || "gpt-4o";
            apiKey = config.apiKey || getApiKey("openai", null);
            temperature = config.temperature || 0.7;
            
            if (!apiKey) {
                // Try to get first available OpenAI key
                const keys = getProviderKeys("openai");
                if (keys.length > 0) {
                    apiKey = keys[0].apiKey;
                    apiKeyId = keys[0].id;
                }
            }
        }

        if (!apiKey) {
            throw new Error("API key not configured. Please set it in the settings.");
        }

        // Call appropriate provider API
        let data;
        let rawResponse = null; // Store raw response for token tracking
        try {
            switch (provider) {
                case "openai":
                    data = await callOpenAIAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature);
                    rawResponse = data; // OpenAI response is already in correct format
                    break;
                case "anthropic":
                    rawResponse = await callAnthropicAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature);
                    // Anthropic returns raw response, convert after tracking
                    data = rawResponse;
                    break;
                case "gemini":
                    rawResponse = await callGeminiAPI(messages, availableNodeTypes, nodesInWorkspace, model, apiKey, temperature);
                    // Gemini returns converted format, need original for tracking
                    // We'll track from the converted format which includes usageMetadata
                    data = rawResponse;
                    break;
                default:
                    throw new Error(`Unsupported provider: ${provider}`);
            }
        } catch (error) {
            // Re-throw with provider context
            if (error.message && !error.message.includes(provider)) {
                throw new Error(`${provider} API Error: ${error.message}`);
            }
            throw error;
        }
        
        // Track token usage (use rawResponse for Gemini, data for others)
        var tokenInfo = null;
        if (RED.aiTokenTracker && data) {
            // Detect operation type from user message
            var operationType = 'question';
            var messageLower = userMessage.toLowerCase();
            if (messageLower.includes('create') || messageLower.includes('make') || messageLower.includes('build') || messageLower.includes('generate')) {
                operationType = 'create_flow';
            } else if (messageLower.includes('update') || messageLower.includes('modify') || messageLower.includes('change') || messageLower.includes('edit') || messageLower.includes('add') || messageLower.includes('remove')) {
                operationType = 'update_flow';
            }
            
            // For Gemini, we need to pass the original response before conversion
            // But callGeminiAPI already converts it, so we track from converted format
            tokenInfo = RED.aiTokenTracker.track(data, provider, model, operationType);
        }
        
        // Handle tool calls (unified across providers)
        const message = data.choices && data.choices[0] ? data.choices[0].message : null;
        
        if (message && message.tool_calls && Array.isArray(message.tool_calls) && message.tool_calls.length > 0) {
            for (const toolCall of message.tool_calls) {
                if (toolCall.type === 'function' && toolCall.function) {
                    const { name, arguments: args } = toolCall.function;
                    let functionArgs;
                    
                    try {
                        // Handle both string and object arguments
                        if (typeof args === 'string') {
                            // Use safeParseJSON to handle malformed JSON
                            functionArgs = safeParseJSON(args);
                            if (!functionArgs) {
                                throw new Error('Failed to parse function arguments as JSON');
                            }
                        } else if (typeof args === 'object') {
                            functionArgs = args;
                        } else {
                            throw new Error('Invalid function arguments format');
                        }
                    } catch (e) {
                        console.error('Failed to parse function arguments:', e, 'Raw args:', args);
                        return {
                            success: false,
                            error: 'Failed to parse function arguments',
                            content: "I encountered an error processing your request. The AI response contained invalid JSON. Please try again."
                        };
                    }

                    const handlers = {
                        normal_reply: handleNormalReply,
                        create_flow: handleCreateFlow,
                        update_flow: handleUpdateFlow
                    };

                    const handler = handlers[name];
                    if (handler) {
                        const result = handler(functionArgs, nodesInWorkspace);
                        if (truncationInfo) {
                            result.truncationInfo = truncationInfo;
                        }
                        if (tokenInfo) {
                            result.tokenUsage = tokenInfo.usage;
                            result.tokenCost = tokenInfo.cost;
                        }
                        return result;
                    } else {
                        console.warn('Unknown handler:', name);
                        const result = handleNormalReply({ response: "I couldn't process your request properly. Unknown function: " + name }, nodesInWorkspace);
                        if (truncationInfo) {
                            result.truncationInfo = truncationInfo;
                        }
                        return result;
                    }
                }
            }
        }
        
        // Handle direct text response
        if (message && message.content) {
            const content = typeof message.content === 'string' ? message.content : 
                          (Array.isArray(message.content) ? message.content.map(c => c.text || c).join('') : 
                          String(message.content || ''));
            
            if (content && content.trim().length > 0) {
                const result = {
                    success: true,
                    isFlow: false,
                    isUpdate: false,
                    content: content
                };
                if (truncationInfo) {
                    result.truncationInfo = truncationInfo;
                }
                if (tokenInfo) {
                    result.tokenUsage = tokenInfo.usage;
                    result.tokenCost = tokenInfo.cost;
                }
                return result;
            }
        }

        // Fallback for other response formats
        if (data.content && Array.isArray(data.content) && data.content.length > 0) {
            const text = data.content[0].text || data.content[0];
            if (text) {
                return {
                    success: true,
                    isFlow: false,
                    isUpdate: false,
                    content: String(text)
                };
            }
        }

        // Last resort - log and return error
        console.error('Unexpected response format:', data);
        return {
            success: false,
            isFlow: false,
            isUpdate: false,
            content: "I received an unexpected response format. Please try again.",
            error: "Unexpected response format"
        };
    }

    // Legacy support
    async function createFlow(userMessage, conversationHistory, availableNodeTypes) {
        return processMessage(userMessage, conversationHistory, availableNodeTypes);
    }

    function init() {
        loadConfig();
        
        // Initialize context manager
        if (RED.aiContextManager) {
            RED.aiContextManager.init();
        }
    }

    return {
        init,
        createFlow,
        processMessage,
        loadConfig,
        applyFlowChanges,
        updateApiKey,
        getApiKey: getApiKey,
        getProviderKeys: getProviderKeys
    };
})(); 
